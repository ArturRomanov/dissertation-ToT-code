{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToT Prompt Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs a simple check on an example from the datasets produced from the notebook ToT-data-ETL based on the MMLU dataset (Hendrycks et al, 2021a; Hendrycks et al, 2021b; Hendrycks et al, 2023) to check if a model with a prompt in the ToT style could produce a better answer than a model without such prompt\n",
    "\n",
    "Please note that different results could be generated for each run of the notebook and you could need to run the notebook a few times to generate similar results as those indicated in this notebook\n",
    "\n",
    "Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "\n",
    "Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021b. Measuring Massive Multitask Language Understanding. ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-27. Available from: https://arxiv.org/pdf/2009.03300.pdf [Accessed 5 August 2024].\n",
    " \n",
    "Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D. and Steinhardt, J., 2023. Aligning AI With Shared Human Values. ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-29. Available from: https://arxiv.org/pdf/2008.02275.pdf [Accessed 5 August 2024]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_train_dataset_path_csv = \"full_train_dataset.csv\"\n",
    "\n",
    "# Code, that is, the loading of the dataset, adapted from: pandas, 2024. pandas.read_csv (v.2.2) [Online]. \n",
    "# Available from: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html [Accessed 17 August 2024].\n",
    "full_train_dataset = pd.read_csv(full_train_dataset_path_csv)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhanced question example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court\n",
      "A. must permit Don to answer if he had objected to Peter's testimony.\n",
      "B. may permit Don to answer, whether or not he had objected to Peter's testimony. \n",
      "C. may permit Don to answer only if he had objected to Peter's testimony.\n",
      "D. cannot permit Don to answer, whether or not he had objected to Peter's testimony\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from: pandas, 2024. pandas.DataFrame.at (v.2.2) [Online]. \n",
    "# Available from: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at [Accessed 5 September 2024].\n",
    "enhanced_question = full_train_dataset.at[0, \"enhanced_question\"]\n",
    "#\n",
    "print(enhanced_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct answer of the enhanced question example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from: pandas, 2024. pandas.DataFrame.at (v.2.2) [Online]. \n",
    "# Available from: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html#pandas.DataFrame.at [Accessed 5 September 2024].\n",
    "letter_answer = full_train_dataset.at[0, \"letter_answer\"]\n",
    "#\n",
    "print(letter_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code, that is, the import, reused from: LangChain, 2023. OllamaLLM [Online]. \n",
    "# Available from: https://python.langchain.com/v0.2/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html [Accessed 1 September 2024].\n",
    "from langchain_ollama import OllamaLLM\n",
    "#\n",
    "\n",
    "# Code, that is, the answer generator, adapted from: LangChain, 2023. OllamaLLM [Online]. \n",
    "# Available from: https://python.langchain.com/v0.2/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html [Accessed 1 September 2024].\n",
    "answer_generator_llm = OllamaLLM(\n",
    "    # Code, that is, the parameter, reused from: LangChain, 2023. OllamaLLM [Online]. \n",
    "    # Available from: https://python.langchain.com/v0.2/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html [Accessed 1 September 2024].\n",
    "    # Code, that is, the value, reused from: Ollama, 2024. mixtral 8x7b-instruct-v0.1-fp16 [Online]. \n",
    "    # Available from: https://ollama.com/library/mixtral:8x7b-instruct-v0.1-fp16 [Accessed 25 September 2024].\n",
    "    model=\"mixtral:8x7b-instruct-v0.1-fp16\"\n",
    "    #\n",
    "    )\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court\n",
      "A. must permit Don to answer if he had objected to Peter's testimony.\n",
      "B. may permit Don to answer, whether or not he had objected to Peter's testimony. \n",
      "C. may permit Don to answer only if he had objected to Peter's testimony.\n",
      "D. cannot permit Don to answer, whether or not he had objected to Peter's testimony\n",
      "What is the answer and the answer letter? It is very important that you provide the correct answer letter in the format of Answer: A, Answer: B, Answer: C or Answer: D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt (lines 1 - 2 in the simple_prompt_to_generate_answer) is based on: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "#\n",
    "# Prompt (lines 1 - 2 in the simple_prompt_to_generate_answer) is adapted and based on: mrspiggot, 2023. langchain_tree.py [computer program].\n",
    "# Available from: https://github.com/mrspiggot/forestOfThoughts/blob/master/langchain_tree.py [Accessed 5 September 2024]. \n",
    "# (mrspiggot, 2023, lines 23 - 25)\n",
    "#\n",
    "# Please note that enhanced_question variable in the simple_prompt_to_generate_answer would include transformed data from: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "simple_prompt_to_generate_answer = f'''\n",
    "{enhanced_question}\n",
    "What is the answer and the answer letter? It is very important that you provide the correct answer letter in the format of Answer: A, Answer: B, Answer: C or Answer: D\n",
    "'''\n",
    "#\n",
    "print(simple_prompt_to_generate_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a base answer based on a simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer is:\n",
      "\n",
      "Answer: D,Cannot permit Don to answer, whether or not he had objected to Peter's testimony.\n",
      "\n",
      "Explanation: In a court of law, evidence that is irrelevant to the case at hand is generally not admissible. The fact that Don and his wife quarreled frequently is not relevant to the breach of contract lawsuit between Peter and Don. Therefore, even if Don had objected to Peter's testimony, the court still cannot permit Don to testify in response that he and his wife never quarreled. This is because the response is also irrelevant and could prejudice the jury against Don or his wife for no legitimate reason.\n",
      "The simple answer generated with 5 retries with the specified format\n"
     ]
    }
   ],
   "source": [
    "retries_for_quality_simple_prompt = 0\n",
    "max_retries_for_quality_simple_prompt = 5\n",
    "while retries_for_quality_simple_prompt < max_retries_for_quality_simple_prompt:\n",
    "    # Code, that is, the answer generation, adapted from: LangChain, 2023. OllamaLLM [Online]. \n",
    "    # Available from: https://python.langchain.com/v0.2/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html [Accessed 1 September 2024].\n",
    "    generated_simple_answer = answer_generator_llm.invoke(simple_prompt_to_generate_answer)\n",
    "    #\n",
    "    print(generated_simple_answer)\n",
    "\n",
    "    # Code is based on several outputs from Mixtral 8x7b Instruct version v0.1, fp16 (pers. comm.) on 03/10/2024 \n",
    "    # from tot_prompt_to_generate_answer prompt in the prompt_tot function in the Prompt section in ToT-data-answer-generator-and-checker notebook, with and without hint_1 and hint_2 \n",
    "    # values for the prompt which are indicated in the code in Generate and check answers subsection in ToT-data-answer-generator-and-checker notebook \n",
    "    # and enhanced_question values from train_dataset in ToT-data-answer-generator-and-checker notebook\n",
    "    # for the prompt (that is, the outputs that could be produced with the code in ToT-data-answer-generator-and-checker notebook) which is based on the MMLU dataset: \n",
    "    # Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "    # Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "    # Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021b. Measuring Massive Multitask Language Understanding. \n",
    "    # ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-27. Available from: https://arxiv.org/pdf/2009.03300.pdf [Accessed 5 August 2024].\n",
    "    # Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D. and Steinhardt, J., 2023. Aligning AI With Shared Human Values. \n",
    "    # ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-29. Available from: https://arxiv.org/pdf/2008.02275.pdf [Accessed 5 August 2024].\n",
    "    # Please note that Mixtral 8x7b Instruct version v0.1, fp16 has been used locally using: \n",
    "    # Ollama, 2024a. Ollama [computer program]. Available from: https://ollama.com [Accessed 1 September 2024].\n",
    "    # Ollama, 2024b. mixtral 8x7b-instruct-v0.1-fp16 [Online]. \n",
    "    # Available from: https://ollama.com/library/mixtral:8x7b-instruct-v0.1-fp16 [Accessed 25 September 2024].\n",
    "    # Code is based on: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "    # Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "    if (f\"Answer: A\" in generated_simple_answer or\n",
    "        f\"Answer: B\" in generated_simple_answer or\n",
    "        f\"Answer: C\" in generated_simple_answer or\n",
    "        f\"Answer: D\" in generated_simple_answer or\n",
    "        f\"answer: A\" in generated_simple_answer or\n",
    "        f\"answer: B\" in generated_simple_answer or\n",
    "        f\"answer: C\" in generated_simple_answer or\n",
    "        f\"answer: D\" in generated_simple_answer or\n",
    "        f\"Answer is A\" in generated_simple_answer or\n",
    "        f\"Answer is B\" in generated_simple_answer or\n",
    "        f\"Answer is C\" in generated_simple_answer or\n",
    "        f\"Answer is D\" in generated_simple_answer or\n",
    "        f\"answer is A\" in generated_simple_answer or\n",
    "        f\"answer is B\" in generated_simple_answer or\n",
    "        f\"answer is C\" in generated_simple_answer or\n",
    "        f\"answer is D\" in generated_simple_answer or\n",
    "        f\"Answer is: A\" in generated_simple_answer or\n",
    "        f\"Answer is: B\" in generated_simple_answer or\n",
    "        f\"Answer is: C\" in generated_simple_answer or\n",
    "        f\"Answer is: D\" in generated_simple_answer or\n",
    "        f\"answer is: A\" in generated_simple_answer or\n",
    "        f\"answer is: B\" in generated_simple_answer or\n",
    "        f\"answer is: C\" in generated_simple_answer or\n",
    "        f\"answer is: D\" in generated_simple_answer):\n",
    "    #\n",
    "        retries_for_quality_simple_prompt = max_retries_for_quality_simple_prompt\n",
    "        print(f\"The simple answer generated with {retries_for_quality_simple_prompt} retries with the specified format\")\n",
    "    else:\n",
    "        retries_for_quality_simple_prompt += 1\n",
    "        print(f\"The simple answer generated with {retries_for_quality_simple_prompt} retries without the specified format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the base answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer generated with a simple prompt is incorrect\n"
     ]
    }
   ],
   "source": [
    "# Code is based on several outputs from Mixtral 8x7b Instruct version v0.1, fp16 (pers. comm.) on 03/10/2024 \n",
    "# from tot_prompt_to_generate_answer prompt in the prompt_tot function in the Prompt section in ToT-data-answer-generator-and-checker notebook, with and without hint_1 and hint_2 \n",
    "# values for the prompt which are indicated in the code in Generate and check answers subsection in ToT-data-answer-generator-and-checker notebook \n",
    "# and enhanced_question values from train_dataset in ToT-data-answer-generator-and-checker notebook\n",
    "# for the prompt (that is, the outputs that could be produced with the code in ToT-data-answer-generator-and-checker notebook) which is based on the MMLU dataset: \n",
    "# Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "# Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021b. Measuring Massive Multitask Language Understanding. \n",
    "# ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-27. Available from: https://arxiv.org/pdf/2009.03300.pdf [Accessed 5 August 2024].\n",
    "# Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D. and Steinhardt, J., 2023. Aligning AI With Shared Human Values. \n",
    "# ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-29. Available from: https://arxiv.org/pdf/2008.02275.pdf [Accessed 5 August 2024].\n",
    "# Please note that Mixtral 8x7b Instruct version v0.1, fp16 has been used locally using: \n",
    "# Ollama, 2024a. Ollama [computer program]. Available from: https://ollama.com [Accessed 1 September 2024].\n",
    "# Ollama, 2024b. mixtral 8x7b-instruct-v0.1-fp16 [Online]. \n",
    "# Available from: https://ollama.com/library/mixtral:8x7b-instruct-v0.1-fp16 [Accessed 25 September 2024].\n",
    "# Code is based on: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "if (f\"Answer: {letter_answer}\" in generated_simple_answer or\n",
    "    f\"answer: {letter_answer}\" in generated_simple_answer or\n",
    "    f\"Answer is {letter_answer}\" in generated_simple_answer or\n",
    "    f\"answer is {letter_answer}\" in generated_simple_answer or\n",
    "    f\"Answer is: {letter_answer}\" in generated_simple_answer or\n",
    "    f\"answer is: {letter_answer}\" in generated_simple_answer):\n",
    "#   \n",
    "    print(\"The answer generated with a simple prompt is correct\")\n",
    "else:\n",
    "    print(\"The answer generated with a simple prompt is incorrect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a ToT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imagine three different experts are answering this question in the Tree of Thoughts style.\n",
      "They will brainstorm and debate the answer step by step reasoning carefully and taking all facts into consideration\n",
      "All experts will write down 1 step of their thinking, then share it with the group.\n",
      "They will each critique their response, and then all the responses of others\n",
      "They will check their answer based on the appropriate rules.\n",
      "Then all experts will go on to the next step and write down this step of their thinking.\n",
      "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts.\n",
      "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred. \n",
      "If any expert realises they're wrong at any point then they acknowledge this and start another train of thought.\n",
      "Each expert will assign a likelihood of their current assertion being correct.\n",
      "Continue until the experts agree on the single most likely answer\n",
      "\n",
      "Use the following template delimited by #####.\n",
      "\n",
      "#####\n",
      "Step 1\n",
      "\n",
      "Expert 1\n",
      "concise thought 1:\n",
      "concise critique of thought 1:\n",
      "probability of thought 1 being correct in percentage:\n",
      "\n",
      "Expert 2\n",
      "concise thought 2:\n",
      "concise critique of thought 2:\n",
      "probability of thought 2 being correct in percentage:\n",
      "\n",
      "Expert 3\n",
      "concise thought 3:\n",
      "concise critique of thought 3:\n",
      "probability of thought 3 being correct in percentage:\n",
      "\n",
      "Step 2\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.1:\n",
      "concise critique of thought 1.1:\n",
      "probability of thought 1.1 being correct in percentage:\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.2:\n",
      "concise critique of thought 1.2:\n",
      "probability of thought 1.2 being correct in percentage:\n",
      "\n",
      "Expert 2\n",
      "concise thought 2.1:\n",
      "concise critique of thought 2.1:\n",
      "probability of thought 2.1 being correct in percentage:\n",
      "\n",
      "Expert 2\n",
      "concise thought 2.2:\n",
      "concise critique of thought 2.2:\n",
      "probability of thought 2.2 being correct in percentage:\n",
      "\n",
      "Expert 3\n",
      "concise thought 3.1:\n",
      "concise critique of thought 3.1:\n",
      "probability of thought 3.1 being correct in percentage:\n",
      "\n",
      "Expert 3\n",
      "concise thought 3.2:\n",
      "concise critique of thought 3.2:\n",
      "probability of thought 3.2 being correct in percentage:\n",
      "\n",
      "Step 3\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.1.1:\n",
      "concise critique of thought 1.1.1:\n",
      "probability of thought 1.1.1 being correct in percentage:\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.2.1:\n",
      "concise critique of thought 1.2.1:\n",
      "probability of thought 1.2.1 being correct in percentage:\n",
      "\n",
      "Expert 2\n",
      "concise thought 2.1.1:\n",
      "concise critique of thought 2.1.1:\n",
      "probability of thought 2.1.1 being correct in percentage:\n",
      "\n",
      "Expert 2\n",
      "concise thought 2.2.1:\n",
      "concise critique of thought 2.2.1:\n",
      "probability of thought 2.2.1 being correct in percentage:\n",
      "\n",
      "Expert 3\n",
      "concise thought 3.1.1:\n",
      "concise critique of thought 3.1.1:\n",
      "probability of thought 3.1.1 being correct in percentage:\n",
      "\n",
      "Expert 3\n",
      "concise thought 3.2.1:\n",
      "concise critique of thought 3.2.1:\n",
      "probability of thought 3.2.1 being correct in percentage:\n",
      "\n",
      "Conclusion: write here the answer which all of the experts agree is the correct answer based on the final thoughts of the experts\n",
      "\n",
      "Answer: write here the answer letter which all of the experts agree is the correct answer based on the final thoughts of the experts\n",
      "#####\n",
      "\n",
      "Very important. The thoughts of experts must be diverse and different, that is, the experts must not repeat what they previously said and the thoughts of the experts should include letters (A, B, C or D) to which the thoughts refer or relate. \n",
      "Very important. In Step 1, each expert must provide 1 thought (3 thoughts in total, that is, concise thought 1, concise thought 2, concise thought 3). \n",
      "Very important. In Step 2, each expert must provide 2 thoughts (6 thoughts in total, that is, concise thought 1.1, concise thought 1.2, concise thought 2.1, concise thought 2.2, concise thought 3.1, concise thought 3.2). \n",
      "Very important. In Step 3, each expert must provide at least 2 thoughts (at least 6 thoughts in total), etc.\n",
      "Very important. The answer letter which all of the experts agree is the correct answer based on the final thoughts of the experts should be in the format of Answer: answer letter which all of the experts agree is the correct answer based on the final thoughts of the experts, for example, Answer: A, Answer: B, Answer: C or Answer: D.\n",
      "\n",
      "The question is: Peter sued Don for breach of contract. The court admitted testimony by Peter that Don and his wife quarreled frequently, a fact of no consequence to the lawsuit. Don seeks to testify in response that he and his wife never quarreled. The court\n",
      "A. must permit Don to answer if he had objected to Peter's testimony.\n",
      "B. may permit Don to answer, whether or not he had objected to Peter's testimony. \n",
      "C. may permit Don to answer only if he had objected to Peter's testimony.\n",
      "D. cannot permit Don to answer, whether or not he had objected to Peter's testimony\n",
      "Think in the Tree of Thoughts style. What is the answer and the answer letter? It is very important that you provide the correct answer letter in the format of Answer: A, Answer: B, Answer: C or Answer: D and it is very important that you provide it only after all the thoughts in step 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt (lines 1 - 11 in the tot_prompt_to_generate_answer) reused and slightly adapted from: mrspiggot, 2023. langchain_tree.py [computer program].\n",
    "# Available from: https://github.com/mrspiggot/forestOfThoughts/blob/master/langchain_tree.py [Accessed 5 September 2024]. \n",
    "# (mrspiggot, 2023, lines 11 - 22)\n",
    "#\n",
    "# Prompt (lines 16 - 99 in the tot_prompt_to_generate_answer, that is, where delimited by #####) is based on: Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y. and Narasimhan, K., 2023. \n",
    "# Tree of Thoughts: Deliberate Problem Solving with Large Language Models. 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 10-16 December 2023, New Orleans. \n",
    "# Ithaca: Cornell University Library, arXiv.org, pp.1-14. Available from: https://arxiv.org/pdf/2305.10601.pdf [Accessed 17 August 2024].\n",
    "#\n",
    "# Prompt (lines 16 - 99 in the tot_prompt_to_generate_answer, that is, where delimited by #####) is based on the approach of how tree is structured: Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y. and Narasimhan, K., 2023. \n",
    "# Tree of Thoughts: Deliberate Problem Solving with Large Language Models. 37th Conference on Neural Information Processing Systems (NeurIPS 2023), 10-16 December 2023, New Orleans. \n",
    "# Ithaca: Cornell University Library, arXiv.org, pp.1-14. Available from: https://arxiv.org/pdf/2305.10601.pdf [Accessed 17 August 2024]. \n",
    "# (for example, Yao et al, 2023, page 2, figure d)\n",
    "#\n",
    "# Prompt (lines 13 - 105, line 109 in the tot_prompt_to_generate_answer) is adapted and based on the ToT pattern according to: Zhang, Z., Ye, Z., Shen, Y. and Gan, C., 2023. \n",
    "# Autonomous Tree-Search Ability of Large Language Models. Ithaca: Cornell University Library, arXiv.org. arXiv [Online]. \n",
    "# Available from: https://arxiv.org/pdf/2310.10686.pdf [Accessed 25 August 2024]. \n",
    "# (Zhang et al, 2023, page 13, C.1)\n",
    "#\n",
    "# Prompt (lines 16 - 106 in the tot_prompt_to_generate_answer) is adapted and based on: mrspiggot, 2023. langchain_tree.py [computer program].\n",
    "# Available from: https://github.com/mrspiggot/forestOfThoughts/blob/master/langchain_tree.py [Accessed 5 September 2024]. \n",
    "# (mrspiggot, 2023, lines 11 - 26)\n",
    "#\n",
    "# Prompt (line 102 in the tot_prompt_to_generate_answer, that is, where indicated about the letters and line 11, line 97, line 99, line 106, line 108, line 109 in the tot_prompt_to_generate_answer) is based on: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "#\n",
    "# Prompt (line 108 in the tot_prompt_to_generate_answer) reused and slightly adapted from: mrspiggot, 2023. langchain_tree.py [computer program].\n",
    "# Available from: https://github.com/mrspiggot/forestOfThoughts/blob/master/langchain_tree.py [Accessed 5 September 2024]. \n",
    "# (mrspiggot, 2023, line 23)\n",
    "#\n",
    "# Prompt (line 109 in the tot_prompt_to_generate_answer) is adapted and based on: mrspiggot, 2023. langchain_tree.py [computer program].\n",
    "# Available from: https://github.com/mrspiggot/forestOfThoughts/blob/master/langchain_tree.py [Accessed 5 September 2024]. \n",
    "# (mrspiggot, 2023, lines 11 - 26)\n",
    "#\n",
    "# Prompt (line 109, that is, before asking about the answer) is based on: Kojima, T., Gu, S.S., Reid, M., Matsuo, Y. and Iwasawa, Y., 2023. \n",
    "# Large Language Models are Zero-Shot Reasoners. 36th Conference on Neural Information Processing Systems (NeurIPS 2022), 28 November 2022 â€“ 9 December 2022, New Orleans. \n",
    "# Ithaca: Cornell University Library, arXiv.org, pp.1-42. Available from: https://arxiv.org/pdf/2205.11916 [Accessed 15 September 2024]. \n",
    "# (Kojima et al, 2023, page 2, figure d)\n",
    "#\n",
    "# Please note that enhanced_question variable in the tot_prompt_to_generate_answer would include transformed data from: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "#\n",
    "tot_prompt_to_generate_answer = f'''\n",
    "Imagine three different experts are answering this question in the Tree of Thoughts style.\n",
    "They will brainstorm and debate the answer step by step reasoning carefully and taking all facts into consideration\n",
    "All experts will write down 1 step of their thinking, then share it with the group.\n",
    "They will each critique their response, and then all the responses of others\n",
    "They will check their answer based on the appropriate rules.\n",
    "Then all experts will go on to the next step and write down this step of their thinking.\n",
    "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts.\n",
    "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred. \n",
    "If any expert realises they're wrong at any point then they acknowledge this and start another train of thought.\n",
    "Each expert will assign a likelihood of their current assertion being correct.\n",
    "Continue until the experts agree on the single most likely answer\n",
    "\n",
    "Use the following template delimited by #####.\n",
    "\n",
    "#####\n",
    "Step 1\n",
    "\n",
    "Expert 1\n",
    "concise thought 1:\n",
    "concise critique of thought 1:\n",
    "probability of thought 1 being correct in percentage:\n",
    "\n",
    "Expert 2\n",
    "concise thought 2:\n",
    "concise critique of thought 2:\n",
    "probability of thought 2 being correct in percentage:\n",
    "\n",
    "Expert 3\n",
    "concise thought 3:\n",
    "concise critique of thought 3:\n",
    "probability of thought 3 being correct in percentage:\n",
    "\n",
    "Step 2\n",
    "\n",
    "Expert 1\n",
    "concise thought 1.1:\n",
    "concise critique of thought 1.1:\n",
    "probability of thought 1.1 being correct in percentage:\n",
    "\n",
    "Expert 1\n",
    "concise thought 1.2:\n",
    "concise critique of thought 1.2:\n",
    "probability of thought 1.2 being correct in percentage:\n",
    "\n",
    "Expert 2\n",
    "concise thought 2.1:\n",
    "concise critique of thought 2.1:\n",
    "probability of thought 2.1 being correct in percentage:\n",
    "\n",
    "Expert 2\n",
    "concise thought 2.2:\n",
    "concise critique of thought 2.2:\n",
    "probability of thought 2.2 being correct in percentage:\n",
    "\n",
    "Expert 3\n",
    "concise thought 3.1:\n",
    "concise critique of thought 3.1:\n",
    "probability of thought 3.1 being correct in percentage:\n",
    "\n",
    "Expert 3\n",
    "concise thought 3.2:\n",
    "concise critique of thought 3.2:\n",
    "probability of thought 3.2 being correct in percentage:\n",
    "\n",
    "Step 3\n",
    "\n",
    "Expert 1\n",
    "concise thought 1.1.1:\n",
    "concise critique of thought 1.1.1:\n",
    "probability of thought 1.1.1 being correct in percentage:\n",
    "\n",
    "Expert 1\n",
    "concise thought 1.2.1:\n",
    "concise critique of thought 1.2.1:\n",
    "probability of thought 1.2.1 being correct in percentage:\n",
    "\n",
    "Expert 2\n",
    "concise thought 2.1.1:\n",
    "concise critique of thought 2.1.1:\n",
    "probability of thought 2.1.1 being correct in percentage:\n",
    "\n",
    "Expert 2\n",
    "concise thought 2.2.1:\n",
    "concise critique of thought 2.2.1:\n",
    "probability of thought 2.2.1 being correct in percentage:\n",
    "\n",
    "Expert 3\n",
    "concise thought 3.1.1:\n",
    "concise critique of thought 3.1.1:\n",
    "probability of thought 3.1.1 being correct in percentage:\n",
    "\n",
    "Expert 3\n",
    "concise thought 3.2.1:\n",
    "concise critique of thought 3.2.1:\n",
    "probability of thought 3.2.1 being correct in percentage:\n",
    "\n",
    "Conclusion: write here the answer which all of the experts agree is the correct answer based on the final thoughts of the experts\n",
    "\n",
    "Answer: write here the answer letter which all of the experts agree is the correct answer based on the final thoughts of the experts\n",
    "#####\n",
    "\n",
    "Very important. The thoughts of experts must be diverse and different, that is, the experts must not repeat what they previously said and the thoughts of the experts should include letters (A, B, C or D) to which the thoughts refer or relate. \n",
    "Very important. In Step 1, each expert must provide 1 thought (3 thoughts in total, that is, concise thought 1, concise thought 2, concise thought 3). \n",
    "Very important. In Step 2, each expert must provide 2 thoughts (6 thoughts in total, that is, concise thought 1.1, concise thought 1.2, concise thought 2.1, concise thought 2.2, concise thought 3.1, concise thought 3.2). \n",
    "Very important. In Step 3, each expert must provide at least 2 thoughts (at least 6 thoughts in total), etc.\n",
    "Very important. The answer letter which all of the experts agree is the correct answer based on the final thoughts of the experts should be in the format of Answer: answer letter which all of the experts agree is the correct answer based on the final thoughts of the experts, for example, Answer: A, Answer: B, Answer: C or Answer: D.\n",
    "\n",
    "The question is: {enhanced_question}\n",
    "Think in the Tree of Thoughts style. What is the answer and the answer letter? It is very important that you provide the correct answer letter in the format of Answer: A, Answer: B, Answer: C or Answer: D and it is very important that you provide it only after all the thoughts in step 3\n",
    "'''\n",
    "#\n",
    "print(tot_prompt_to_generate_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an answer based on a ToT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #####\n",
      "Step 1\n",
      "\n",
      "Expert 1\n",
      "concise thought 1A: The court's decision to admit testimony irrelevant to the lawsuit can be appealed as a potential prejudicial error. Don should have objected to Peter's testimony at the time of its delivery.\n",
      "concise critique of thought 1A: This initial thought assumes that Don did not object, and focuses on the impact of that assumed omission. However, it is still unknown whether Don actually objected or not.\n",
      "probability of thought 1A being correct in percentage: 60%\n",
      "\n",
      "Expert 2\n",
      "concise thought 1B: The admissibility of evidence in this case depends on its relevance and potential for prejudice. Frequent quarreling between Don and his wife may be character evidence, which is generally not admissible in contract disputes.\n",
      "concise critique of thought 1B: While correct, this thought does not directly address the issue of whether Don should be permitted to respond to Peter's testimony.\n",
      "probability of thought 1B being correct in percentage: 70%\n",
      "\n",
      "Expert 3\n",
      "concise thought 1C: The court has broad discretion in deciding what evidence to admit, and its decision is usually not disturbed on appeal unless it was arbitrary or capricious.\n",
      "concise critique of thought 1C: This initial thought establishes a legal principle but fails to apply it to the specific situation faced by Don and Peter.\n",
      "probability of thought 1C being correct in percentage: 50%\n",
      "\n",
      "Step 2\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.1A: If Don did not object, he may be barred from challenging the admission of Peter's testimony due to waiver or estoppel principles.\n",
      "concise critique of thought 1.1A: This thought assumes that Don failed to object, which has not been definitively established.\n",
      "probability of thought 1.1A being correct in percentage: 60%\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.2A: If the court permitted Peter's irrelevant testimony, it may be more inclined to allow Don to respond, even if he did not object.\n",
      "concise critique of thought 1.2A: This thought assumes that the court will favor balance and fairness, which might not always be the case.\n",
      "probability of thought 1.2A being correct in percentage: 70%\n",
      "\n",
      "Expert 2\n",
      "concise thought 1.1B: The impact of Peter's testimony on Don's right to respond may depend on whether it was direct or hearsay evidence.\n",
      "concise critique of thought 1.1B: This thought introduces a new factor, but fails to explain its significance in this situation.\n",
      "probability of thought 1.1B being correct in percentage: 40%\n",
      "\n",
      "Expert 2\n",
      "concise thought 1.2B: In some jurisdictions, the court may have discretion to allow rebuttal evidence even if it was not initially admitted over an objection.\n",
      "concise critique of thought 1.2B: This thought raises a possibility but does not provide sufficient context or analysis.\n",
      "probability of thought 1.2B being correct in percentage: 50%\n",
      "\n",
      "Expert 3\n",
      "concise thought 1.1C: The court's decision to allow or disallow rebuttal evidence may hinge on its assessment of the potential for prejudice and confusion among jurors.\n",
      "concise critique of thought 1.1C: This thought identifies another relevant factor but does not consider how it might influence the final decision.\n",
      "probability of thought 1.1C being correct in percentage: 60%\n",
      "\n",
      "Expert 3\n",
      "concise thought 1.2C: Even if Don did object, the court may still deny his request to respond based on the relevance and potential for prejudice of his proposed testimony.\n",
      "concise critique of thought 1.2C: This thought contradicts an earlier assumption made in expert 3's initial thought; it indicates a lack of consistency or clarity.\n",
      "probability of thought 1.2C being correct in percentage: 50%\n",
      "\n",
      "Step 3\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.1.1A: Don should argue that his proposed testimony is relevant to counter the potential prejudicial impact of Peter's statement on the jury's perception of his character.\n",
      "probability of thought 1.1.1A being correct in percentage: 80%\n",
      "\n",
      "Expert 1\n",
      "concise thought 1.2.1A: The court may exercise its discretion to allow Don to respond if it determines that the probative value of his testimony outweighs any potential for prejudice or confusion.\n",
      "probability of thought 1.2.1A being correct in percentage: 80%\n",
      "\n",
      "Expert 2\n",
      "concise thought 1.1.1B: The court should consider whether Don's proposed testimony would be more probative than merely instructing the jury to disregard Peter's statement.\n",
      "probability of thought 1.1.1B being correct in percentage: 70%\n",
      "\n",
      "Expert 2\n",
      "concise thought 1.2.1B: The court may deny Don's request if it determines that his testimony would be cumulative or merely serve to provoke undue sympathy from the jury.\n",
      "probability of thought 1.2.1B being correct in percentage: 70%\n",
      "\n",
      "Expert 3\n",
      "concise thought 1.1.1C: The court's decision should ultimately prioritize ensuring a fair trial for both parties and minimizing any potential for confusion or misleading the jury.\n",
      "probability of thought 1.1.1C being correct in percentage: 90%\n",
      "\n",
      "Expert 3\n",
      "concise thought 1.2.1C: Regardless of whether Don objected, the court has the authority to exclude irrelevant or prejudicial evidence from both parties' testimonies.\n",
      "probability of thought 1.2.1C being correct in percentage: 90%\n",
      "\n",
      "Based on the final thoughts, the answer is B: may permit Don to answer, whether or not he had objected to Peter's testimony. This answer reflects the court's broad discretion to manage evidence and ensure a fair trial for both parties.\n",
      "The tot answer generated with 5 retries with the specified format\n"
     ]
    }
   ],
   "source": [
    "retries_for_quality_tot_prompt = 0\n",
    "max_retries_for_quality_tot_prompt = 5\n",
    "while retries_for_quality_tot_prompt < max_retries_for_quality_tot_prompt:\n",
    "    # Code, that is, the answer generation, adapted from: LangChain, 2023. OllamaLLM [Online]. \n",
    "    # Available from: https://python.langchain.com/v0.2/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html [Accessed 1 September 2024].\n",
    "    generated_tot_answer = answer_generator_llm.invoke(tot_prompt_to_generate_answer)\n",
    "    #\n",
    "    print(generated_tot_answer)\n",
    "\n",
    "    # Code is based on several outputs from Mixtral 8x7b Instruct version v0.1, fp16 (pers. comm.) on 03/10/2024 \n",
    "    # from tot_prompt_to_generate_answer prompt in the prompt_tot function in the Prompt section in ToT-data-answer-generator-and-checker notebook, with and without hint_1 and hint_2 \n",
    "    # values for the prompt which are indicated in the code in Generate and check answers subsection in ToT-data-answer-generator-and-checker notebook \n",
    "    # and enhanced_question values from train_dataset in ToT-data-answer-generator-and-checker notebook\n",
    "    # for the prompt (that is, the outputs that could be produced with the code in ToT-data-answer-generator-and-checker notebook) which is based on the MMLU dataset: \n",
    "    # Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "    # Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "    # Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021b. Measuring Massive Multitask Language Understanding. \n",
    "    # ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-27. Available from: https://arxiv.org/pdf/2009.03300.pdf [Accessed 5 August 2024].\n",
    "    # Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D. and Steinhardt, J., 2023. Aligning AI With Shared Human Values. \n",
    "    # ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-29. Available from: https://arxiv.org/pdf/2008.02275.pdf [Accessed 5 August 2024].\n",
    "    # Please note that Mixtral 8x7b Instruct version v0.1, fp16 has been used locally using: \n",
    "    # Ollama, 2024a. Ollama [computer program]. Available from: https://ollama.com [Accessed 1 September 2024].\n",
    "    # Ollama, 2024b. mixtral 8x7b-instruct-v0.1-fp16 [Online]. \n",
    "    # Available from: https://ollama.com/library/mixtral:8x7b-instruct-v0.1-fp16 [Accessed 25 September 2024].\n",
    "    # Code is based on: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "    # Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "    if (f\"Answer: A\" in generated_tot_answer or\n",
    "        f\"Answer: B\" in generated_tot_answer or\n",
    "        f\"Answer: C\" in generated_tot_answer or\n",
    "        f\"Answer: D\" in generated_tot_answer or\n",
    "        f\"answer: A\" in generated_tot_answer or\n",
    "        f\"answer: B\" in generated_tot_answer or\n",
    "        f\"answer: C\" in generated_tot_answer or\n",
    "        f\"answer: D\" in generated_tot_answer or\n",
    "        f\"Answer is A\" in generated_tot_answer or\n",
    "        f\"Answer is B\" in generated_tot_answer or\n",
    "        f\"Answer is C\" in generated_tot_answer or\n",
    "        f\"Answer is D\" in generated_tot_answer or\n",
    "        f\"answer is A\" in generated_tot_answer or\n",
    "        f\"answer is B\" in generated_tot_answer or\n",
    "        f\"answer is C\" in generated_tot_answer or\n",
    "        f\"answer is D\" in generated_tot_answer or\n",
    "        f\"Answer is: A\" in generated_tot_answer or\n",
    "        f\"Answer is: B\" in generated_tot_answer or\n",
    "        f\"Answer is: C\" in generated_tot_answer or\n",
    "        f\"Answer is: D\" in generated_tot_answer or\n",
    "        f\"answer is: A\" in generated_tot_answer or\n",
    "        f\"answer is: B\" in generated_tot_answer or\n",
    "        f\"answer is: C\" in generated_tot_answer or\n",
    "        f\"answer is: D\" in generated_tot_answer):\n",
    "    #\n",
    "        retries_for_quality_tot_prompt = max_retries_for_quality_tot_prompt\n",
    "        print(f\"The tot answer generated with {retries_for_quality_tot_prompt} retries with the specified format\")\n",
    "    else:\n",
    "        retries_for_quality_tot_prompt += 1\n",
    "        print(f\"The tot answer generated with {retries_for_quality_tot_prompt} retries without the specified format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer generated with a tot prompt is correct\n"
     ]
    }
   ],
   "source": [
    "# Code is based on several outputs from Mixtral 8x7b Instruct version v0.1, fp16 (pers. comm.) on 03/10/2024 \n",
    "# from tot_prompt_to_generate_answer prompt in the prompt_tot function in the Prompt section in ToT-data-answer-generator-and-checker notebook, with and without hint_1 and hint_2 \n",
    "# values for the prompt which are indicated in the code in Generate and check answers subsection in ToT-data-answer-generator-and-checker notebook \n",
    "# and enhanced_question values from train_dataset in ToT-data-answer-generator-and-checker notebook\n",
    "# for the prompt (that is, the outputs that could be produced with the code in ToT-data-answer-generator-and-checker notebook) which is based on the MMLU dataset: \n",
    "# Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "# Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021b. Measuring Massive Multitask Language Understanding. \n",
    "# ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-27. Available from: https://arxiv.org/pdf/2009.03300.pdf [Accessed 5 August 2024].\n",
    "# Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D. and Steinhardt, J., 2023. Aligning AI With Shared Human Values. \n",
    "# ICLR 2021, 4 May 2021, Vienna. Ithaca: Cornell University Library, arXiv.org, pp.1-29. Available from: https://arxiv.org/pdf/2008.02275.pdf [Accessed 5 August 2024].\n",
    "# Please note that Mixtral 8x7b Instruct version v0.1, fp16 has been used locally using: \n",
    "# Ollama, 2024a. Ollama [computer program]. Available from: https://ollama.com [Accessed 1 September 2024].\n",
    "# Ollama, 2024b. mixtral 8x7b-instruct-v0.1-fp16 [Online]. \n",
    "# Available from: https://ollama.com/library/mixtral:8x7b-instruct-v0.1-fp16 [Accessed 25 September 2024].\n",
    "# Code is based on: Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D. and Steinhardt, J., 2021a. \n",
    "# Dataset Card for MMLU [Online]. s.l.: Hugging Face. Available from: https://huggingface.co/datasets/cais/mmlu [Accessed 5 August 2024].\n",
    "if (f\"Answer: {letter_answer}\" in generated_tot_answer or\n",
    "    f\"answer: {letter_answer}\" in generated_tot_answer or\n",
    "    f\"Answer is {letter_answer}\" in generated_tot_answer or\n",
    "    f\"answer is {letter_answer}\" in generated_tot_answer or\n",
    "    f\"Answer is: {letter_answer}\" in generated_tot_answer or\n",
    "    f\"answer is: {letter_answer}\" in generated_tot_answer):\n",
    "#   \n",
    "    print(\"The answer generated with a tot prompt is correct\")\n",
    "else:\n",
    "    print(\"The answer generated with a tot prompt is incorrect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
